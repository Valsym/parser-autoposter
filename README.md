# parser-autoposter
<b>Задача:</b></b>
Для горнолыжного портала fanski.ru потребовалось создать список страниц с описанием всех (или почти всех) горнолыжных курортов трех Европейских стран: Австрии, Франции и Швейцарии. 

В декабре 2015 - январе 2016 гг. эта задача была успешно решена благодаря двум созданным блокам: парсеру контента и блоку автоматической публикации статей (автопостеру) , пример: http://fanski.ru/category/ski-resort/aus-ski </b>
Всего было опубликовано описаний к 198 курортам Австрии, 218 - Франции и 141- Швейцарии.</b>

В данном репозитории привожу описание этих двух блоков с кодом, написанным мной на PHP. 

Кроме того, после публикации списка описаний для этих 557 курортов, вознилко естественное желание добавить в курорты данные о погоде и возможность сортироваки списка, таким образом, были разработаны еще два блока. </b>
Первый позволял публиковать на страничке описания кадого курорта текущие данные о погоде и прогноз на ближайшие 5 дней:  </b>
Давление, мм рт.ст.</b>
Видимость, км</b>
Облачность, %</b>
Температура, °C (ночь/день)</b>
</b>
Второй блок позволяет выполять сортировку прямо на сайте список курортов по следующим параметрам:</b>
Странам </b>
Регионам стран, </b>
Общему километражу трасс (от/до), </b>
Вертикальному перепаду перепаду высот (от/до),</b>
Названию конкретного курорта.</b>
</b>
<b>1. Парсер контента.</b>

1.1 Предподготовка (сбор ссылок, откуда будем парсить контент).
Заходим на сайт http://www.onthesnow.co.uk выбираем интересующий нас регион, например вся Австрия и попадаем на страницу:<br/>
http://www.onthesnow.co.uk/austria/ski-resorts.html

Любым удобным способом копируем станицу с контентом и выдираем из него все ссылки на все горнолыжные курорты Австрии. Формируем примерно такой список:<br/>
file-allink.csv

1.2 Собственно сам прасер: read-link.php предельно прост (хотя кода и много).

Как видно из кода, основная логика работы парсера такова: </b>
парсер берет в цикле ссылку из file-allink.csv</b>
подготавливает запрос к сайту-донору, с которого будем парсить контент, </b>
делает запрос и получает данные: $source = request(...)</b>
Затем вызывает функцию makesnd($source,$fp); которая записывает спаршенные данные в файл fileresaus.csv</b>

Подробнее о функции request:<br/>
$source = request($data[0],$prox,$usag,$ref); <br/>
здесь $data[0] - это ссылка на страницу с курортом на сайте onthesnow, <br/>
$prox - случайно выбранная из списка прокси, <br/>
$usag - случайно выбранный из списка браузер, <br/>
$ref - первоначальная точка входа на сайт http://www.onthesnow.co.uk<br/>
Это сделано для того, чтобы сайт-донор нас не забанил, поскольку запросов было много и подряд.<br/>

Список прокси $proxy = file('http://fanski.ru/wp-content/uploads/sn-dop/proxy-list.csv'); формировался из прокси, взятых из открытых источников и затем чекался на валидность прямо непосредственно перед парсингом.

Браузеры брались из списка актуальных на момент написания парсера (см. chooseBrowser.php)

Собственно сам код функции request хорошо прокомментирован и пояснений почти не требует:  <br/>
Происходит инициализация сеанса CURL. Затем curl_setopt — устанавливает параметры для сеанса CURL и после формирования всех прокси, кук, рефереров, заголовков таймаутов и т.п. вызывется собственно загрузка страницы и выдача её браузеру<br/>
curl_exec($ch);<br/>
после чего сеанс завершается curl_close($ch); до следующего шага цикла.

Итак контент спаршен, далее дело техники - его нужно извлечь и сформировать массив необходимых нам данных. 
Этим как раз и занимается функция <br/>
function makesnd($source, $fp){ // makesnd = make site need data<br/>
с помощью регулярных выражений.<br/>
Формируется довольно внушительный массив данных (ключи говорят за себя сами, надеюсь понятно):<br/>
Наименование курорта, перепы высот, кол-во подъемников разных типов (бугели, креселки, гондолы, 2х,3х,4х,6ти и 8-местные и т.п.), общий километраж трасс и километраж по типам - черные синие, зелены трассы, кол-во сноупарков, их площади, даты открытия/закрытия, инфо (контактные данные), геограическая долгота и широта курорта.
$arrall = array();<br/>

$item['name'] = $name;<br/>
$item['max'] = $max;<br/>
$item['min'] = $min;<br/>
$item['drop'] = $drop;<br/>
$item['lift'] = $lift;<br/>
$item['gond'] = $gond;<br/>
$item['lift8s'] = $lift8s;
$item['lift6s'] = $lift6s;
$item['lift4s'] = $lift4s;
$item['lift4'] = $lift4;
$item['lift3'] = $lift3;
$item['lift2'] = $lift2;
$item['liftb'] = $liftb;
$item['tsl'] = $tsl;
$item['green'] = $green;
$item['blue'] = $blue;
$item['red'] = $red;<br/>
$item['black'] = $black;<br/>
$item['kms'] = $kms;<br/>
$item['spark'] = $spark;<br/>
$item['slong'] = $slong;<br/>
$item['sqr'] = $sqr;<br/>
$item['sqrs'] = $sqrs;<br/>
$item['kmss'] = $kmss;<br/>
$item['openclose'] = $openclose;<br/>
$item['price'] = $price;<br/>
//$item['info'] = $info;<br/>
$item['lat'] = $lat;<br/>
$item['lon'] = $lon;<br/>

array_push($arrall, $item);<br/>

В конце функция makesnd из этой простыни данных формирует строку текста и записывает в файл fileresaus.csv

<b>2. Блок автоматической публикации статей на сайте fanski.ru (wordpress):</b> <br/>
post-circle1.php<br/>
Предварительно для каждого курорта из списка выше парсились лого, картинки и схема трасс (с помощью ContentDownloader), а сами курорты сортировались по регионам: Каринтия, Тироль, Верхняя Австрия и т.д. 

На сайте были предварительно сформированы Категории типа $category_slug = "Carinthia"; (Tyrol, Styria,  Salzburg и т.д.) и  на хостинг залиты файлы с отсортированными по регионам списками с данными о курортах (пример: Carinthia.csv), переформированные из общих списков данных по странам (из п.1).

В цикле читалась инфа из соответствующего файла: <br/>
fopen('http://fanski.ru/post/'.$category_slug.'.csv', "r");

Формировался заголовок статьи, описание, ключевые слова и тело.<br/>
Также в тело вставлялись заглушки для будущих шорткодов, для возможности подключения вывода данных о погоде и сервисов бронирования:<br/>
$mod=1;<br/>
$body .='[snowd res='.$name1.' mod='.$mod.']';<br/>
$body .='[pogoda res='.$name1.' lat='.$lat.' lon='.$lon.' mod='.$mod.']';<br/>

Кроме того, сразу же формировались произвольные поля для БД wordpress:<br/>
	add_post_meta($post_id, 'kms', $kms);<br/>
	add_post_meta($post_id, 'drop', $drop);<br/>
	add_post_meta($post_id, 'lat', $lat);<br/>
	add_post_meta($post_id, 'lon', $lon);<br/>
	для возможности сортировки курортов по перепаду высот и дальности расстояния от заданной географической точки (с айта донора парсились и записывались данные геолокации - географические широта и долгота курорта).

А также, как можно заметить, в тело поста вставлялся фрейм iframe партнерки travelpayouts.com с геоданными курорта, позволяющий осуществлять поиск ближайшего жилья на онлайн карте.
	
Вот что в итоге получилось, как пример первый попавшийся курорт Австрии:<br/>
http://fanski.ru/ski-resort/aus-ski/salzburg/abtenau

<b>3. Блок погоды.</b><br/>
До некоторого времени на всех страничках курортов также отображалась инфа о погоде от сервиса https://api.worldweatheronline.com Но поскольку он создавал большую нагрузку на хостинг, то был отключен: pogoda.php

<b>3. Блок сортировки курортов.</b><br/>
Форма сортировки: archive.php
Функция go_filter.php

Список файлов прилагается (в открытый доступ выложены все файлы, кроме двух: по понятным причинам коды парсера и автопостера добавлены в .gitignore, могу открыть их по запросу потенциального работодателя):<br/>
file-allink.csv<br/>
fileresaus.csv<br/>
read-link.php<br/>
proxy-list.csv<br/>
chooseBrowser.php<br/>
post-circle1.php<br/>
Carinthia.csv<br/>
pogoda.php<br/>
go_filter.php<br/>
archive.php<br/>

2015 - 2017 © Валерий Симонов
