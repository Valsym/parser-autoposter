# parser-autoposter
Задача:
Для сайта fanski.ru потребовалось создать список страниц с описанием всех (или почти всех) горнолыжных курортов Европейских стран: Австрии, Франции и Швейцарии. 

В декабре 2015 - январе 2016 гг. благодаря двум созданным блокам: парсер контента и блок автоматической публикации статей задача была успешно решена, пример: http://fanski.ru/category/ski-resort/aus-ski 
Всего было опубликовано описаний: к 198 курортам Австрии, 218 - Франции и 141- Швейцарии.

В данном репозитории привожу описание этих двух блоков с кодом, написанным мной на PHP.

<b>1. Парсер контента.</b>

1.1 Предподготовка (сбор ссылок, откуда будем парсить контент).
Заходим на сайт http://www.onthesnow.co.uk выбираем интересующий нас регион, например вся Австрия и попадаем на страницу:<br/>
http://www.onthesnow.co.uk/austria/ski-resorts.html

Любым удобным способом копируем станицу с контентом и выдираем из него все ссылки на все горнолыжные курорты Австрии. Формируем примерно такой список:<br/>
file-allink.csv

1.2 Собственно сам прасер: read-link.php предельно прост (хотя кода и много).

Как видно из кода, парсер берет в цикле ссылку из file-allink.csv

подготавливает запрос к сайту, с которого будем парсить контент, делает запрос и получает данные:
$source = request(...)

Затем вызывает функцию makesnd($source,$fp); которая записывает спаршенные данные в файл fileresaus.csv

Подробнее о функции request:<br/>
$source = request($data[0],$prox,$usag,$ref); <br/>
здесь $data[0] - это ссылка на страницу с курортом на сайте onthesnow, <br/>
$prox - случайно выбранная из списка прокси, <br/>
$usag - случайно выбранный из списка браузер, <br/>
$ref - первоначальная точка входа на сайт http://www.onthesnow.co.uk<br/>
Это сделано, чтобы сайт нас не забанил поскольку запросов будет много и подряд.<br/>

Список прокси $proxy = file('http://fanski.ru/wp-content/uploads/sn-dop/proxy-list.csv'); формировался из прокси, взятых из открытых источников и затем чекался на валидность прямо непосредственно перед парсингом.

Браузеры брались из списка актуальных на момент написания парсера (см. chooseBrowser.php)

Собственно сам код request хорошо прокомментирован и пояснений почти не требует:  <br/>
Происходит инициализация сеанса CURL. Затем curl_setopt — устанавливает параметры для сеанса CURL и после формирования всех прокси, кук, рефереров, заголовков таймаутов и т.п. вызывется собственно загрузка страницы и выдача её браузеру<br/>
curl_exec($ch);<br/>
после чего сеанс завершается curl_close($ch); до следующего шага цикла.

Итак контент спаршен, далее дело техники - его нужно извлечь и сформировать массив необходимых нам данных. 
Этим как раз и занимается функция <br/>
function makesnd($source, $fp){ // makesnd = make site need data<br/>
с помощью регулярных выражений.<br/>
Формируется довольно внушительный массив данных (ключи говорят за себя сами, надеюсь понятно):<br/>
$arrall = array();<br/>

$item['name'] = $name;<br/>
$item['max'] = $max;<br/>
$item['min'] = $min;<br/>
$item['drop'] = $drop;<br/>
$item['lift'] = $lift;<br/>
$item['gond'] = $gond;<br/>
$item['lift8s'] = $lift8s;
$item['lift6s'] = $lift6s;
$item['lift4s'] = $lift4s;
$item['lift4'] = $lift4;
$item['lift3'] = $lift3;
$item['lift2'] = $lift2;
$item['liftb'] = $liftb;
$item['tsl'] = $tsl;
$item['green'] = $green;
$item['blue'] = $blue;
$item['red'] = $red;<br/>
$item['black'] = $black;<br/>
$item['kms'] = $kms;<br/>
$item['spark'] = $spark;<br/>
$item['slong'] = $slong;<br/>
$item['sqr'] = $sqr;<br/>
$item['sqrs'] = $sqrs;<br/>
$item['kmss'] = $kmss;<br/>
$item['openclose'] = $openclose;<br/>
$item['price'] = $price;<br/>
//$item['info'] = $info;<br/>
$item['lat'] = $lat;<br/>
$item['lon'] = $lon;<br/>

array_push($arrall, $item);<br/>

В конце из этой простыни формируется строка текста и записывается в файл fileresaus.csv

<b>2. Блок автоматической публикации статей на сайте fanski.ru (wordpress):</b> <br/>
post-circle1.php<br/>
Предварительно для каждого курорта из списка выше парсились лого, картинки и схема трасс (с помощью ContentDownloader), а сами курорты сортировались по регионам: Каринтия, Тироль, Верхняя Австрия и т.д. 

На сайте были предварительно сформированы Категории типа $category_slug = "Carinthia"; (Tyrol, Styria,  Salzburg и т.д.) и  на хостинг залиты отсортированные списки с данными о курортах по категориям (пример: Carinthia.csv)

В цикле читалась инфа из соответствующего файла: <br/>
fopen('http://fanski.ru/post/'.$category_slug.'.csv', "r");

Формировался заголовок статьи, описание, ключевые слова и тело.<br/>
Также в тело вставлялись заглушки для будущих шорткодов, для возможности подключения вывода данных о погоде и сервисов бронирования:<br/>
$mod=1;<br/>
$body .='[snowd res='.$name1.' mod='.$mod.']';<br/>
$body .='[pogoda res='.$name1.' lat='.$lat.' lon='.$lon.' mod='.$mod.']';<br/>

Кроме того, сразу же формировались произвольные поля для БД wordpress:<br/>
	add_post_meta($post_id, 'kms', $kms);<br/>
	add_post_meta($post_id, 'drop', $drop);<br/>
	add_post_meta($post_id, 'lat', $lat);<br/>
	add_post_meta($post_id, 'lon', $lon);<br/>
	для возможности сортировки курортов по перепаду высот и дальности расстояния от заданной географической точки (с айта донора парсились и записывались данные геолокации - географические широта и долгота курорта).

А также, как можно заметить, в тело поста вставлялся фрейм iframe партнерки travelpayouts.com с геоданными курорта, позволяющий осуществлять поиск ближайшего жилья на онлайн карте.
	
Вот что в итоге получилось, как пример первый попавшийся курорт Австрии:<br/>
http://fanski.ru/ski-resort/aus-ski/salzburg/abtenau

До некоторого времени на всех страничках курортов также отображалась инфа о погоде от сервиса https://api.worldweatheronline.com Но поскольку он создавал большую нагрузку на хостинг, то был отключен: pogoda.php

Список файлов прилагается:<br/>
file-allink.csv<br/>
fileresaus.csv<br/>
read-link.php<br/>
proxy-list.csv<br/>
chooseBrowser.php<br/>
post-circle1.php<br/>
Carinthia.csv<br/>
pogoda.php<br/>

2015 - 2017 © Валерий Симонов
